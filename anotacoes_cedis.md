## üì¶ Configura√ß√£o de Containers

### üß† Sobre

Trata-se de uma arquitetura multimodal utilizando LLMs.
Atualmente s√£o usadas tr√™s ferramentas principais:

* **Ollama**
* **OpenWebUI**
* **LLMlite**

#### üîó Integra√ß√£o entre os servi√ßos

* **OpenWebUI**
  Interface gr√°fica do usu√°rio.
  Conectada ao **LLMlite** pela rede local na porta **4000**.

* **LLMlite**
  Atua como maestro/gerenciador respons√°vel por decidir qual modelo de IA ser√° utilizado.
  Conecta-se aos containers do **Ollama** em diferentes portas.

* **Ollama**
  Respons√°vel pelo download e execu√ß√£o dos modelos de IA.

---

### üê≥ Criando Containers

#### OpenWebUI

```bash
docker run --detach --interactive --tty --name ctrOpenweb --workdir /openweb --network host andrelanna/openweb-ui:0.6.4 bash
```
#### Ollama

```bash
docker run --detach --interactive --tty --name ctrOllama --workdir /ollama --network host andrelanna/ollama bash
```
#### LLMlite

```bash
docker run -d \
    --name ctrLLMlite \
    --network host \
    -v $(pwd)/litellm_config.yaml:/app/config.yaml \
    docker.litellm.ai/berriai/litellm:main-latest \
    --config /app/config.yaml
```    

### üê≥ Rodando Containers

#### OpenWebUI

```bash
docker start ctrOpenweb 
docker exec --interactive --tty --name ctrOpenweb bash
open-webui serve
```
#### Ollama

```bash
docker start ctrOllama 
docker exec  --interactive --tty --name ctrOllama bash
ollama serve
OLLAMA_HOST=127.0.0.1:11435 ollama serve #INICIA UM SEGUNDO CONTAINER NA PORTA 11435
```
